{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/liviamurray/photometry_preprocessing/sabatini-glm-workflow/notebooks', '/Users/liviamurray/opt/anaconda3/envs/photometry/lib/python311.zip', '/Users/liviamurray/opt/anaconda3/envs/photometry/lib/python3.11', '/Users/liviamurray/opt/anaconda3/envs/photometry/lib/python3.11/lib-dynload', '', '/Users/liviamurray/opt/anaconda3/envs/photometry/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os \n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from sglm import utils, glm_fit\n",
    "\n",
    "#d1 - T430\n",
    "#d2 - T434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's create a new project. The project directory will create a data and results folder and a config file.\n",
    "\n",
    "#### You will need to edit the config file with the particular glm params you wish to use. Fields that are necessary to edit are: predictors, predictors_shift_bounds, response, and the glm_keyword_args.\n",
    "\n",
    "#### You will also need to move your data into the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/Neurobio/MICROSCOPE/Livia/glm_output/D1_all_glm/config.yaml'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = 'D1_all_glm'\n",
    "project_dir = r'/Volumes/Neurobio/MICROSCOPE/Livia/glm_output'\n",
    "\n",
    "utils.create_new_project(project_name, project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data should conform to the following convention and be saved as a *.csv:\n",
    "\n",
    "Indices / Unique Row Identifiers:\n",
    "* SessionName -- Any order is acceptable\n",
    "* TrialNumber-- Must be in chronological order, but does not need to start from zero\n",
    "* Timestamp -- Must be in chronological order, but does not need to start from zero\n",
    "\n",
    "Columns (Predictors + Responses):\n",
    "* Predictors - binary\n",
    "* Reponses - e.g. neural responses (analog or binary)\n",
    "\n",
    "Example, shown below is dummy data depicting a trial_0 that last four response timestamps:\n",
    "| SessionName | TrialNumber | Timestamp | predictor_1 | predictor_2 | predictor_3 | response_1 | response_2 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| session_0 | trial_0 | -1 | 0 | 0 | 0 | 1 | 0.3 |\n",
    "| session_0 | trial_0 | 0 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_0 | 1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_0 | trial_0 | 2 | 0 | 1 | 0 | 1 | 0.3 |\n",
    "| session_0 | trial_1 | -2 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_1 | -1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_0 | trial_1 | 0 | 1 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_1 | 1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_0 | 5 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_0 | 6 | 1 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_0 | 7 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_0 | 8 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_1 | 9 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_1 | 10 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's get set up to start our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.path.join(project_dir, project_name)\n",
    "files = os.listdir(project_path)\n",
    "\n",
    "assert 'data' in files, 'data folder not found! {}'.format(files)\n",
    "assert 'results' in files, 'results folder not found! {}'.format(files)\n",
    "assert 'config.yaml' in files, 'config.yaml not found! {}'.format(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If needed, use the following function to combine multiple sessions into one csv. You will need a filename you wish to call your output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_csv = 'output.csv'\n",
    "output_csv = 'D1_all_glmFormat.csv'\n",
    "\n",
    "# utils.combine_csvs(project_path, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll open the data and set the columns you wish to use as fixed indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataframe has 1789648 rows and 17 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Cue</th>\n",
       "      <th>ENL_Licks_L</th>\n",
       "      <th>ENL_Licks_R</th>\n",
       "      <th>Select_L</th>\n",
       "      <th>Select_R</th>\n",
       "      <th>ENLP_L</th>\n",
       "      <th>ENLP_R</th>\n",
       "      <th>Consumption_R_R</th>\n",
       "      <th>Consumption_R_L</th>\n",
       "      <th>Cons_more_R_R</th>\n",
       "      <th>Cons_more_R_L</th>\n",
       "      <th>Consumption_UR_R</th>\n",
       "      <th>Consumption_UR_L</th>\n",
       "      <th>Cons_more_UR_R</th>\n",
       "      <th>Cons_more_UR_L</th>\n",
       "      <th>z_grnR</th>\n",
       "      <th>z_grnL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SessionName</th>\n",
       "      <th>TrialNumber</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">T429_2023_07_12</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2.0</th>\n",
       "      <th>50.697830</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.718474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.739118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.759762</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.780406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">T442_2023_10_04</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">6913.0</th>\n",
       "      <th>2310.062899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.548984</td>\n",
       "      <td>-0.562397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310.083543</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.615215</td>\n",
       "      <td>-0.683538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310.104187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.679485</td>\n",
       "      <td>-0.781860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310.124831</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.705743</td>\n",
       "      <td>-0.835182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310.145475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.708598</td>\n",
       "      <td>-0.854935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1789648 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Cue  ENL_Licks_L  ENL_Licks_R  \\\n",
       "SessionName     TrialNumber Timestamp                                    \n",
       "T429_2023_07_12 2.0         50.697830    0.0          0.0          0.0   \n",
       "                            50.718474    0.0          0.0          0.0   \n",
       "                            50.739118    0.0          0.0          0.0   \n",
       "                            50.759762    0.0          0.0          0.0   \n",
       "                            50.780406    0.0          0.0          0.0   \n",
       "...                                      ...          ...          ...   \n",
       "T442_2023_10_04 6913.0      2310.062899  0.0          0.0          0.0   \n",
       "                            2310.083543  0.0          0.0          0.0   \n",
       "                            2310.104187  0.0          0.0          0.0   \n",
       "                            2310.124831  0.0          0.0          0.0   \n",
       "                            2310.145475  0.0          0.0          0.0   \n",
       "\n",
       "                                         Select_L  Select_R  ENLP_L  ENLP_R  \\\n",
       "SessionName     TrialNumber Timestamp                                         \n",
       "T429_2023_07_12 2.0         50.697830           0         0       0       0   \n",
       "                            50.718474           0         0       0       0   \n",
       "                            50.739118           0         0       0       0   \n",
       "                            50.759762           0         0       0       0   \n",
       "                            50.780406           0         0       0       0   \n",
       "...                                           ...       ...     ...     ...   \n",
       "T442_2023_10_04 6913.0      2310.062899         0         0       0       0   \n",
       "                            2310.083543         0         0       0       0   \n",
       "                            2310.104187         0         0       0       0   \n",
       "                            2310.124831         0         0       0       0   \n",
       "                            2310.145475         0         0       0       0   \n",
       "\n",
       "                                         Consumption_R_R  Consumption_R_L  \\\n",
       "SessionName     TrialNumber Timestamp                                       \n",
       "T429_2023_07_12 2.0         50.697830                0.0              0.0   \n",
       "                            50.718474                0.0              0.0   \n",
       "                            50.739118                0.0              0.0   \n",
       "                            50.759762                0.0              0.0   \n",
       "                            50.780406                0.0              0.0   \n",
       "...                                                  ...              ...   \n",
       "T442_2023_10_04 6913.0      2310.062899              0.0              0.0   \n",
       "                            2310.083543              0.0              0.0   \n",
       "                            2310.104187              0.0              0.0   \n",
       "                            2310.124831              0.0              0.0   \n",
       "                            2310.145475              0.0              0.0   \n",
       "\n",
       "                                         Cons_more_R_R  Cons_more_R_L  \\\n",
       "SessionName     TrialNumber Timestamp                                   \n",
       "T429_2023_07_12 2.0         50.697830              0.0            0.0   \n",
       "                            50.718474              0.0            0.0   \n",
       "                            50.739118              0.0            0.0   \n",
       "                            50.759762              0.0            0.0   \n",
       "                            50.780406              0.0            0.0   \n",
       "...                                                ...            ...   \n",
       "T442_2023_10_04 6913.0      2310.062899            0.0            0.0   \n",
       "                            2310.083543            0.0            0.0   \n",
       "                            2310.104187            0.0            0.0   \n",
       "                            2310.124831            0.0            0.0   \n",
       "                            2310.145475            0.0            0.0   \n",
       "\n",
       "                                         Consumption_UR_R  Consumption_UR_L  \\\n",
       "SessionName     TrialNumber Timestamp                                         \n",
       "T429_2023_07_12 2.0         50.697830                 0.0               0.0   \n",
       "                            50.718474                 0.0               0.0   \n",
       "                            50.739118                 0.0               0.0   \n",
       "                            50.759762                 0.0               0.0   \n",
       "                            50.780406                 0.0               0.0   \n",
       "...                                                   ...               ...   \n",
       "T442_2023_10_04 6913.0      2310.062899               0.0               0.0   \n",
       "                            2310.083543               0.0               0.0   \n",
       "                            2310.104187               0.0               0.0   \n",
       "                            2310.124831               0.0               0.0   \n",
       "                            2310.145475               0.0               0.0   \n",
       "\n",
       "                                         Cons_more_UR_R  Cons_more_UR_L  \\\n",
       "SessionName     TrialNumber Timestamp                                     \n",
       "T429_2023_07_12 2.0         50.697830               0.0             0.0   \n",
       "                            50.718474               0.0             0.0   \n",
       "                            50.739118               0.0             0.0   \n",
       "                            50.759762               0.0             0.0   \n",
       "                            50.780406               0.0             0.0   \n",
       "...                                                 ...             ...   \n",
       "T442_2023_10_04 6913.0      2310.062899             0.0             0.0   \n",
       "                            2310.083543             0.0             0.0   \n",
       "                            2310.104187             0.0             0.0   \n",
       "                            2310.124831             0.0             0.0   \n",
       "                            2310.145475             0.0             0.0   \n",
       "\n",
       "                                           z_grnR    z_grnL  \n",
       "SessionName     TrialNumber Timestamp                        \n",
       "T429_2023_07_12 2.0         50.697830         NaN       NaN  \n",
       "                            50.718474         NaN       NaN  \n",
       "                            50.739118         NaN       NaN  \n",
       "                            50.759762         NaN       NaN  \n",
       "                            50.780406         NaN       NaN  \n",
       "...                                           ...       ...  \n",
       "T442_2023_10_04 6913.0      2310.062899 -0.548984 -0.562397  \n",
       "                            2310.083543 -0.615215 -0.683538  \n",
       "                            2310.104187 -0.679485 -0.781860  \n",
       "                            2310.124831 -0.705743 -0.835182  \n",
       "                            2310.145475 -0.708598 -0.854935  \n",
       "\n",
       "[1789648 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = os.path.join(project_path, 'data', output_csv)\n",
    "index_col = ['SessionName', 'TrialNumber', 'Timestamp']\n",
    "\n",
    "df = utils.read_data(input_file, index_col)\n",
    "\n",
    "print('Your dataframe has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can now explore and add to the dataframe. As an example, you may want to add various \"predictors\" or \"features\" to explore. You can use the example below as inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Identify the individual licks that have specific meaning in the tasks: \n",
    "# #lick 1, lick 2 and lick 3 are \"operant licks\" on different training days\n",
    "# #licknon1-3 are all the other licks\n",
    "\n",
    "# df_source = df.copy()\n",
    "# srs_lick = df_source.groupby(['SessionName', 'TrialNumber'])['Lick'].cumsum()\n",
    "# srs_lick_count = srs_lick * df_source['Lick']\n",
    "# df_lick_count_dummies = pd.get_dummies(srs_lick_count).drop(0, axis=1)\n",
    "# df_lick_count_dummies = df_lick_count_dummies[[1,2,3]]\n",
    "# df_lick_count_dummies['non1-3'] = df_source['Lick'] - df_lick_count_dummies.sum(axis=1)\n",
    "# df_lick_count_dummies.columns = [f'lick_{original_column_name}' for original_column_name in df_lick_count_dummies.columns]\n",
    "\n",
    "# # Columns lick and lick_1, lick_2, lick_3, lick_non-13 should not all be used together\n",
    "# # as predictors because of multicollinearity.\n",
    "# df_source = pd.concat([df_source, df_lick_count_dummies], axis=1)\n",
    "# df_source\n",
    "\n",
    "# assert np.all(df_source['Lick'] == df_source[['lick_1', 'lick_2', 'lick_3', 'lick_non1-3']].sum(axis=1)), 'Column lick should equal the sum of all other lick columns.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friendly reminder, the df we have imported is mutli-index, meaning, it's organization is dependent on 3-columns that we have set in index_col. Therefore, we can use \"groupby\" if you need to split the organization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reIndex = df_source.groupby(level=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your fitting paramaters and set up your train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Project': {'project_name': 'D1_all_glm',\n",
       "  'project_path': '/Volumes/Neurobio/MICROSCOPE/Livia/glm_output/D1_all_glm'},\n",
       " 'glm_params': {'glm_keyword_args': {'alpha': [0.05,\n",
       "    0.075,\n",
       "    0.08,\n",
       "    0.1,\n",
       "    0.2,\n",
       "    0.3,\n",
       "    0.4,\n",
       "    0.5,\n",
       "    0.6,\n",
       "    0.7,\n",
       "    0.8],\n",
       "   'cv': 5,\n",
       "   'fit_intercept': True,\n",
       "   'l1_ratio': [0.005,\n",
       "    0.0075,\n",
       "    0.008,\n",
       "    0.009,\n",
       "    0.01,\n",
       "    0.02,\n",
       "    0.03,\n",
       "    0.04,\n",
       "    0.05,\n",
       "    0.075,\n",
       "    0.08,\n",
       "    0.1],\n",
       "   'max_iter': 10000,\n",
       "   'n_alphas': 100,\n",
       "   'n_jobs': -1,\n",
       "   'score_metric': 'r2',\n",
       "   'selection': 'cyclic',\n",
       "   'warm_start': False},\n",
       "  'predictors': ['Cue',\n",
       "   'ENL_Licks_L',\n",
       "   'ENL_Licks_R',\n",
       "   'Select_L',\n",
       "   'Select_R',\n",
       "   'ENLP_L',\n",
       "   'ENLP_R',\n",
       "   'Consumption_R_R',\n",
       "   'Cons_more_R_R',\n",
       "   'Consumption_R_L',\n",
       "   'Cons_more_R_L',\n",
       "   'Consumption_UR_R',\n",
       "   'Cons_more_UR_R',\n",
       "   'Consumption_UR_L',\n",
       "   'Cons_more_UR_L'],\n",
       "  'predictors_shift_bounds': {'Cue': [-3, 3],\n",
       "   'ENL_Licks_L': [-3, 3],\n",
       "   'ENL_Licks_R': [-3, 3],\n",
       "   'Select_L': [-3, 3],\n",
       "   'Select_R': [-3, 3],\n",
       "   'ENLP_L': [-3, 3],\n",
       "   'ENLP_R': [-3, 3],\n",
       "   'Consumption_R_R': [-3, 3],\n",
       "   'Cons_more_R_R': [-3, 3],\n",
       "   'Consumption_R_L': [-3, 3],\n",
       "   'Cons_more_R_L': [-3, 3],\n",
       "   'Consumption_UR_R': [-3, 3],\n",
       "   'Cons_more_UR_R': [-3, 3],\n",
       "   'Consumption_UR_L': [-3, 3],\n",
       "   'Cons_more_UR_L': [-3, 3]},\n",
       "  'predictors_shift_bounds_default': [-50, 100],\n",
       "  'response': ['z_grnR'],\n",
       "  'type': 'Normal'},\n",
       " 'train_test_split': {'test_size': 0.2, 'train_size': 0.8}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = os.path.join(project_path, 'config.yaml')\n",
    "config = utils.load_config(config_file)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift responses and predictors. If you do not want to shift your predictors by an amount you set, feel free to comment out the entire \"predictors_shift_bounds\" in config.yaml. We will then use the default set when we created the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataframe was shifted using: [('Cue', [-3, 3]), ('ENL_Licks_L', [-3, 3]), ('ENL_Licks_R', [-3, 3]), ('Select_L', [-3, 3]), ('Select_R', [-3, 3]), ('ENLP_L', [-3, 3]), ('ENLP_R', [-3, 3]), ('Consumption_R_R', [-3, 3]), ('Cons_more_R_R', [-3, 3]), ('Consumption_R_L', [-3, 3]), ('Cons_more_R_L', [-3, 3]), ('Consumption_UR_R', [-3, 3]), ('Cons_more_UR_R', [-3, 3]), ('Consumption_UR_L', [-3, 3]), ('Cons_more_UR_L', [-3, 3])]\n"
     ]
    }
   ],
   "source": [
    "response_shift, df_predictors_shift, shifted_params = glm_fit.shift_predictors(config, df)\n",
    "print('Your dataframe was shifted using: {}'.format(shifted_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_shift \n",
    "temp = response_shift.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your test/train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 1317213 rows and 105 columns\n",
      "Testing data has 329304 rows and 105 columns\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = glm_fit.split_data(df_predictors_shift, temp, config)\n",
    "\n",
    "print('Training data has {} rows and {} columns'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Testing data has {} rows and {} columns'.format(X_test.shape[0], X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test1 = (y_test.values).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we're ready to run our GLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have two different options. If you know which params you would like to use, you can use the glm_fit.fit_glm function. If you would like tune your hyperparams to determine which are the best to use, you can use the glm_fit.fit_tuned_glm function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the model\n",
    "# model, y_pred, score, beta, intercept, sparse_beta = glm_fit.fit_glm(config, X_train, X_test, y_train, y_test)\n",
    "# print('Your model can account for {} percent of your data'.format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred: [-0.01895279 -0.01895279 -0.01895279 ... -0.01895279 -0.01895279\n",
      " -0.01895279]\n",
      "y: [-1.23502479 -0.53241151 -0.43062487 ...  0.07630479  0.60218541\n",
      " -0.28818469]\n",
      "Your model can account for 1.3622700810245414 percent of your data\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with cross validation: remember, your alphas and l1_ratios should be lists\n",
    "tuned_model, y_pred, score, beta, best_params = glm_fit.fit_tuned_glm(config, X_train, X_test, y_train, y_test)\n",
    "print('Your model can account for {} percent of your data'.format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.05, 'l1_ratio': 0.005}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.0129437838088062 -state\n",
    "1.002032663595287 -state\n",
    "1.0056594783224626 -state\n",
    "\n",
    "\n",
    "4.058554671042813 - reward\n",
    "\n",
    "\n",
    "5.296818236678524 - alpha': 0.05, 'l1_ratio': 0.01, rewards\n",
    "5.365408986535803 ^^\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Create your model dictonary, this should include all the information you wish to save\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: model,\n\u001b[1;32m      3\u001b[0m               \u001b[39m'\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m'\u001b[39m: y_pred,\n\u001b[1;32m      4\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m: score,\n\u001b[1;32m      5\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m'\u001b[39m: beta,\n\u001b[1;32m      6\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mintercept\u001b[39m\u001b[39m'\u001b[39m: intercept,\n\u001b[1;32m      7\u001b[0m               \u001b[39m'\u001b[39m\u001b[39msparse_beta\u001b[39m\u001b[39m'\u001b[39m: sparse_beta,}\n\u001b[1;32m      9\u001b[0m \u001b[39m#Save your model dictionary\u001b[39;00m\n\u001b[1;32m     10\u001b[0m glm_fit\u001b[39m.\u001b[39msave_model(model_dict, config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Create your model dictonary, this should include all the information you wish to save\n",
    "model_dict = {'model': model,\n",
    "              'y_pred': y_pred,\n",
    "              'score': score,\n",
    "              'beta': beta,\n",
    "              'intercept': intercept,\n",
    "              'sparse_beta': sparse_beta,}\n",
    "\n",
    "#Save your model dictionary\n",
    "glm_fit.save_model(model_dict, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm_fit.plot_and_save(config, y_pred, y_test, beta, df_predictors_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
