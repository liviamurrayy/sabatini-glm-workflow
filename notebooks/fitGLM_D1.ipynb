{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\Livia\\\\Desktop\\\\photometry_liv\\\\photometry_preprocessing\\\\sabatini-glm-workflow\\\\notebooks', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\python311.zip', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\DLLs', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\Lib', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm', '', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\Livia\\\\.conda\\\\envs\\\\glm\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os \n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from sglm import utils, glm_fit\n",
    "\n",
    "#d1 - T430\n",
    "#d2 - T434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's create a new project. The project directory will create a data and results folder and a config file.\n",
    "\n",
    "#### You will need to edit the config file with the particular glm params you wish to use. Fields that are necessary to edit are: predictors, predictors_shift_bounds, response, and the glm_keyword_args.\n",
    "\n",
    "#### You will also need to move your data into the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory already exists!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\research.files.med.harvard.edu\\\\\\\\Neurobio\\\\\\\\MICROSCOPE\\\\\\\\Livia\\\\\\\\glm_output\\\\A2a_sh_noITI_glm\\\\config.yaml'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_name = 'A2a_sh_noITI_glm'\n",
    "project_dir = r'\\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Livia\\\\glm_output' # windows\n",
    "# project_dir = r'/Volumes/Neurobio/MICROSCOPE/Livia/glm_output' # mac\n",
    "\n",
    "utils.create_new_project(project_name, project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data should conform to the following convention and be saved as a *.csv:\n",
    "\n",
    "Indices / Unique Row Identifiers:\n",
    "* SessionName -- Any order is acceptable\n",
    "* TrialNumber-- Must be in chronological order, but does not need to start from zero\n",
    "* Timestamp -- Must be in chronological order, but does not need to start from zero\n",
    "\n",
    "Columns (Predictors + Responses):\n",
    "* Predictors - binary\n",
    "* Reponses - e.g. neural responses (analog or binary)\n",
    "\n",
    "Example, shown below is dummy data depicting a trial_0 that last four response timestamps:\n",
    "| SessionName | TrialNumber | Timestamp | predictor_1 | predictor_2 | predictor_3 | response_1 | response_2 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| session_0 | trial_0 | -1 | 0 | 0 | 0 | 1 | 0.3 |\n",
    "| session_0 | trial_0 | 0 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_0 | 1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_0 | trial_0 | 2 | 0 | 1 | 0 | 1 | 0.3 |\n",
    "| session_0 | trial_1 | -2 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_1 | -1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_0 | trial_1 | 0 | 1 | 0 | 0 | 0 | 1.4 |\n",
    "| session_0 | trial_1 | 1 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_0 | 5 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_0 | 6 | 1 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_0 | 7 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_0 | 8 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "| session_1 | trial_1 | 9 | 0 | 0 | 0 | 0 | 1.4 |\n",
    "| session_1 | trial_1 | 10 | 0 | 0 | 0 | 1 | 2.3 |\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's get set up to start our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = os.path.join(project_dir, project_name)\n",
    "files = os.listdir(project_path)\n",
    "\n",
    "assert 'data' in files, 'data folder not found! {}'.format(files)\n",
    "assert 'results' in files, 'results folder not found! {}'.format(files)\n",
    "assert 'config.yaml' in files, 'config.yaml not found! {}'.format(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If needed, use the following function to combine multiple sessions into one csv. You will need a filename you wish to call your output_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A2a_sh_noITI_glmFormat.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = False\n",
    "if left:\n",
    "    # output_csv = 'output.csv'\n",
    "    p_split = project_name.split(\"_\")\n",
    "    p_name = p_split[0][:len(p_split[0])-1]\n",
    "    name = p_name +\"_\"+ p_split[1]\n",
    "    print(name)\n",
    "    output_csv = name +'Format.csv'\n",
    "else: output_csv = project_name +'Format.csv'\n",
    "\n",
    "output_csv\n",
    "# utils.combine_csvs(project_path, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll open the data and set the columns you wish to use as fixed indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataframe has 1408040 rows and 15 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Cue</th>\n",
       "      <th>Select_L</th>\n",
       "      <th>Select_R</th>\n",
       "      <th>ENLP_L</th>\n",
       "      <th>ENLP_R</th>\n",
       "      <th>Consumption_R_R</th>\n",
       "      <th>Consumption_R_L</th>\n",
       "      <th>Cons_more_R_R</th>\n",
       "      <th>Cons_more_R_L</th>\n",
       "      <th>Consumption_UR_R</th>\n",
       "      <th>Consumption_UR_L</th>\n",
       "      <th>Cons_more_UR_R</th>\n",
       "      <th>Cons_more_UR_L</th>\n",
       "      <th>z_grnR</th>\n",
       "      <th>z_grnL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SessionName</th>\n",
       "      <th>TrialNumber</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">T434_2023_08_11</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2824.0</th>\n",
       "      <th>351.519867</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058768</td>\n",
       "      <td>0.137816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351.540511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015933</td>\n",
       "      <td>0.033778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351.561155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.089473</td>\n",
       "      <td>-0.064548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351.581798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.163984</td>\n",
       "      <td>-0.115921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351.602442</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.226307</td>\n",
       "      <td>-0.109918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">T433_2023_08_01</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">658.0</th>\n",
       "      <th>1594.485473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594.506117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594.526761</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594.547405</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594.568049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408040 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Cue  Select_L  Select_R  ENLP_L  \\\n",
       "SessionName     TrialNumber Timestamp                                      \n",
       "T434_2023_08_11 2824.0      351.519867   0.0         0         0       0   \n",
       "                            351.540511   0.0         0         0       0   \n",
       "                            351.561155   0.0         0         0       0   \n",
       "                            351.581798   0.0         0         0       0   \n",
       "                            351.602442   0.0         0         0       0   \n",
       "...                                      ...       ...       ...     ...   \n",
       "T433_2023_08_01 658.0       1594.485473  0.0         0         0       0   \n",
       "                            1594.506117  0.0         0         0       0   \n",
       "                            1594.526761  0.0         0         0       0   \n",
       "                            1594.547405  0.0         0         0       0   \n",
       "                            1594.568049  0.0         0         0       0   \n",
       "\n",
       "                                         ENLP_R  Consumption_R_R  \\\n",
       "SessionName     TrialNumber Timestamp                              \n",
       "T434_2023_08_11 2824.0      351.519867        0              0.0   \n",
       "                            351.540511        0              0.0   \n",
       "                            351.561155        0              0.0   \n",
       "                            351.581798        0              0.0   \n",
       "                            351.602442        0              0.0   \n",
       "...                                         ...              ...   \n",
       "T433_2023_08_01 658.0       1594.485473       0              0.0   \n",
       "                            1594.506117       0              0.0   \n",
       "                            1594.526761       0              0.0   \n",
       "                            1594.547405       0              0.0   \n",
       "                            1594.568049       0              0.0   \n",
       "\n",
       "                                         Consumption_R_L  Cons_more_R_R  \\\n",
       "SessionName     TrialNumber Timestamp                                     \n",
       "T434_2023_08_11 2824.0      351.519867               0.0            0.0   \n",
       "                            351.540511               0.0            0.0   \n",
       "                            351.561155               0.0            0.0   \n",
       "                            351.581798               0.0            0.0   \n",
       "                            351.602442               0.0            0.0   \n",
       "...                                                  ...            ...   \n",
       "T433_2023_08_01 658.0       1594.485473              0.0            0.0   \n",
       "                            1594.506117              0.0            0.0   \n",
       "                            1594.526761              0.0            0.0   \n",
       "                            1594.547405              0.0            0.0   \n",
       "                            1594.568049              0.0            0.0   \n",
       "\n",
       "                                         Cons_more_R_L  Consumption_UR_R  \\\n",
       "SessionName     TrialNumber Timestamp                                      \n",
       "T434_2023_08_11 2824.0      351.519867             0.0               0.0   \n",
       "                            351.540511             0.0               0.0   \n",
       "                            351.561155             0.0               0.0   \n",
       "                            351.581798             0.0               0.0   \n",
       "                            351.602442             0.0               0.0   \n",
       "...                                                ...               ...   \n",
       "T433_2023_08_01 658.0       1594.485473            0.0               0.0   \n",
       "                            1594.506117            0.0               0.0   \n",
       "                            1594.526761            0.0               0.0   \n",
       "                            1594.547405            0.0               0.0   \n",
       "                            1594.568049            0.0               0.0   \n",
       "\n",
       "                                         Consumption_UR_L  Cons_more_UR_R  \\\n",
       "SessionName     TrialNumber Timestamp                                       \n",
       "T434_2023_08_11 2824.0      351.519867                0.0             0.0   \n",
       "                            351.540511                0.0             0.0   \n",
       "                            351.561155                0.0             0.0   \n",
       "                            351.581798                0.0             0.0   \n",
       "                            351.602442                0.0             0.0   \n",
       "...                                                   ...             ...   \n",
       "T433_2023_08_01 658.0       1594.485473               0.0             0.0   \n",
       "                            1594.506117               0.0             0.0   \n",
       "                            1594.526761               0.0             0.0   \n",
       "                            1594.547405               0.0             0.0   \n",
       "                            1594.568049               0.0             0.0   \n",
       "\n",
       "                                         Cons_more_UR_L    z_grnR    z_grnL  \n",
       "SessionName     TrialNumber Timestamp                                        \n",
       "T434_2023_08_11 2824.0      351.519867              0.0  0.058768  0.137816  \n",
       "                            351.540511              0.0 -0.015933  0.033778  \n",
       "                            351.561155              0.0 -0.089473 -0.064548  \n",
       "                            351.581798              0.0 -0.163984 -0.115921  \n",
       "                            351.602442              0.0 -0.226307 -0.109918  \n",
       "...                                                 ...       ...       ...  \n",
       "T433_2023_08_01 658.0       1594.485473             0.0       NaN       NaN  \n",
       "                            1594.506117             0.0       NaN       NaN  \n",
       "                            1594.526761             0.0       NaN       NaN  \n",
       "                            1594.547405             0.0       NaN       NaN  \n",
       "                            1594.568049             0.0       NaN       NaN  \n",
       "\n",
       "[1408040 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = os.path.join(project_path, 'data', output_csv)\n",
    "index_col = ['SessionName', 'TrialNumber', 'Timestamp']\n",
    "\n",
    "df = utils.read_data(input_file, index_col)\n",
    "\n",
    "print('Your dataframe has {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can now explore and add to the dataframe. As an example, you may want to add various \"predictors\" or \"features\" to explore. You can use the example below as inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Identify the individual licks that have specific meaning in the tasks: \n",
    "# #lick 1, lick 2 and lick 3 are \"operant licks\" on different training days\n",
    "# #licknon1-3 are all the other licks\n",
    "\n",
    "# df_source = df.copy()\n",
    "# srs_lick = df_source.groupby(['SessionName', 'TrialNumber'])['Lick'].cumsum()\n",
    "# srs_lick_count = srs_lick * df_source['Lick']\n",
    "# df_lick_count_dummies = pd.get_dummies(srs_lick_count).drop(0, axis=1)\n",
    "# df_lick_count_dummies = df_lick_count_dummies[[1,2,3]]\n",
    "# df_lick_count_dummies['non1-3'] = df_source['Lick'] - df_lick_count_dummies.sum(axis=1)\n",
    "# df_lick_count_dummies.columns = [f'lick_{original_column_name}' for original_column_name in df_lick_count_dummies.columns]\n",
    "\n",
    "# # Columns lick and lick_1, lick_2, lick_3, lick_non-13 should not all be used together\n",
    "# # as predictors because of multicollinearity.\n",
    "# df_source = pd.concat([df_source, df_lick_count_dummies], axis=1)\n",
    "# df_source\n",
    "\n",
    "# assert np.all(df_source['Lick'] == df_source[['lick_1', 'lick_2', 'lick_3', 'lick_non1-3']].sum(axis=1)), 'Column lick should equal the sum of all other lick columns.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friendly reminder, the df we have imported is mutli-index, meaning, it's organization is dependent on 3-columns that we have set in index_col. Therefore, we can use \"groupby\" if you need to split the organization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reIndex = df_source.groupby(level=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your fitting paramaters and set up your train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Project': {'project_name': 'A2a_shuffled_glm',\n",
       "  'project_path': '/Volumes/Neurobio/MICROSCOPE/Livia/glm_output/A2a_shuffled_glm'},\n",
       " 'glm_params': {'glm_keyword_args': {'alpha': 0.0025,\n",
       "   'cv': 5,\n",
       "   'fit_intercept': True,\n",
       "   'l1_ratio': 0.00025,\n",
       "   'max_iter': 1000,\n",
       "   'n_alphas': 100,\n",
       "   'n_jobs': -1,\n",
       "   'score_metric': 'r2',\n",
       "   'selection': 'cyclic',\n",
       "   'warm_start': False},\n",
       "  'predictors': ['Cue',\n",
       "   'Select_L',\n",
       "   'Select_R',\n",
       "   'ENLP_L',\n",
       "   'ENLP_R',\n",
       "   'Consumption_R_R',\n",
       "   'Cons_more_R_R',\n",
       "   'Consumption_R_L',\n",
       "   'Cons_more_R_L',\n",
       "   'Consumption_UR_R',\n",
       "   'Cons_more_UR_R',\n",
       "   'Consumption_UR_L',\n",
       "   'Cons_more_UR_L'],\n",
       "  'predictors_shift_bounds': {'Cue': [-75, 75],\n",
       "   'Select_L': [-75, 75],\n",
       "   'Select_R': [-75, 75],\n",
       "   'ENLP_L': [-75, 75],\n",
       "   'ENLP_R': [-75, 75],\n",
       "   'Consumption_R_R': [-75, 75],\n",
       "   'Cons_more_R_R': [-75, 75],\n",
       "   'Consumption_R_L': [-75, 75],\n",
       "   'Cons_more_R_L': [-75, 75],\n",
       "   'Consumption_UR_R': [-75, 75],\n",
       "   'Cons_more_UR_R': [-75, 75],\n",
       "   'Consumption_UR_L': [-75, 75],\n",
       "   'Cons_more_UR_L': [-75, 75]},\n",
       "  'predictors_shift_bounds_default': [-50, 100],\n",
       "  'response': ['z_grnR'],\n",
       "  'type': 'Normal'},\n",
       " 'train_test_split': {'test_size': 0.2, 'train_size': 0.8}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = os.path.join(project_path, 'config.yaml')\n",
    "config = utils.load_config(config_file)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift responses and predictors. If you do not want to shift your predictors by an amount you set, feel free to comment out the entire \"predictors_shift_bounds\" in config.yaml. We will then use the default set when we created the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataframe was shifted using: [('Cue', [-75, 75]), ('Select_L', [-75, 75]), ('Select_R', [-75, 75]), ('ENLP_L', [-75, 75]), ('ENLP_R', [-75, 75]), ('Consumption_R_R', [-75, 75]), ('Cons_more_R_R', [-75, 75]), ('Consumption_R_L', [-75, 75]), ('Cons_more_R_L', [-75, 75]), ('Consumption_UR_R', [-75, 75]), ('Cons_more_UR_R', [-75, 75]), ('Consumption_UR_L', [-75, 75]), ('Cons_more_UR_L', [-75, 75])]\n"
     ]
    }
   ],
   "source": [
    "response_shift, df_predictors_shift, shifted_params = glm_fit.shift_predictors(config, df)\n",
    "print('Your dataframe was shifted using: {}'.format(shifted_params))\n",
    "# sparse array -> shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparse array - by row\n",
    "import scipy\n",
    "sparse_df = scipy.sparse.csr_array(df_predictors_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1350438x1963 sparse array of type '<class 'numpy.float64'>'\n",
       "\twith 14350819 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_shift \n",
    "temp = response_shift.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your test/train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 1080350 rows and 1963 columns\n",
      "Testing data has 270088 rows and 1963 columns\n"
     ]
    }
   ],
   "source": [
    "# X_train,X_test, y_train, y_test = glm_fit.split_data(df_predictors_shift, temp, config) #changed from df_predictors_shift to sparse_df! \n",
    "X_train,X_test, y_train, y_test = glm_fit.split_data(sparse_df, temp, config) #changed from df_predictors_shift to sparse_df! \n",
    "\n",
    "print('Training data has {} rows and {} columns'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('Testing data has {} rows and {} columns'.format(X_test.shape[0], X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test1 = (y_test.values).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we're ready to run our GLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have two different options. If you know which params you would like to use, you can use the glm_fit.fit_glm function. If you would like tune your hyperparams to determine which are the best to use, you can use the glm_fit.fit_tuned_glm function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred: [-0.212907    0.75664413  0.54706519 ...  0.65708319 -0.29851659\n",
      " -0.44439106]\n",
      "y: [-0.59453422 -0.94069645  0.24037615 ...  0.51996924 -0.9316393\n",
      " -0.95964176]\n",
      "Your model can account for 18.33482477078866 percent of your data\n"
     ]
    }
   ],
   "source": [
    "# # Fit the model\n",
    "model, y_pred, score, beta, intercept, sparse_beta = glm_fit.fit_glm(config, X_train, X_test, y_train, y_test)\n",
    "print('Your model can account for {} percent of your data'.format(score*100))\n",
    "modeltype = \"fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with cross validation: remember, your alphas and l1_ratios should be lists\n",
    "# tuned_model, y_pred, score, beta, best_params = glm_fit.fit_tuned_glm(config, X_train, X_test, y_train, y_test)\n",
    "# print('Your model can account for {} percent of your data'.format(score*100))\n",
    "# modeltype = 'tuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Ridge model\n",
    "# ridge_model, y_pred, score, beta, intercept = glm_fit.fit_ridge(config, X_train, X_test, y_train, y_test)\n",
    "# print('Your model can account for {} percent of your data'.format(score*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Ridge model with cross validation: remember, your alphas should be a list\n",
    "# tuned_ridge_model, y_pred, score, beta, best_params = glm_fit.fit_tuned_ridge(config, X_train, X_test, y_train, y_test)\n",
    "# print('Your model can account for {} percent of your data'.format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spikes_with_prediction(spikes, predicted_spikes, dt,\n",
    "                                nt=50, t0=120, **kws):\n",
    "  \"\"\"Plot actual and predicted spike counts.\n",
    "\n",
    "  Args:\n",
    "    spikes (1D array): Vector of actual spike counts\n",
    "    predicted_spikes (1D array): Vector of predicted spike counts\n",
    "    dt (number): Duration of each time bin.\n",
    "    nt (number): Number of time bins to plot\n",
    "    t0 (number): Index of first time bin to plot.\n",
    "    show (boolean): To plt.show or not the plot.\n",
    "    kws: Pass additional keyword arguments to plot()\n",
    "\n",
    "  \"\"\"\n",
    "  t = np.arange(t0, t0 + nt) * dt\n",
    "\n",
    "  f, ax = plt.subplots()\n",
    "  lines = ax.stem(t, spikes[:nt])\n",
    "  plt.setp(lines, color=\".5\")\n",
    "  lines[-1].set_zorder(1)\n",
    "  kws.setdefault(\"linewidth\", 3)\n",
    "  yhat, = ax.plot(t, predicted_spikes[:nt], **kws)\n",
    "  ax.set(\n",
    "      xlabel=\"Time (s)\",\n",
    "      ylabel=\"Spikes\",\n",
    "  )\n",
    "  ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "  ax.legend([lines[0], yhat], [\"Spikes\", \"Predicted\"])\n",
    "  plt.show()\n",
    "\n",
    "# plot_spikes_with_prediction(y_test, y_pred, df.Timestamp[1] - df.Timestamp[0])\n",
    "# fig = plt.figure(1)\n",
    "# scale = 200\n",
    "# plt.plot(np.arange(0, len(y_test))[0:scale], y_test[0:scale], color='lightblue', label='test')\n",
    "# plt.plot(np.arange(0, len(y_test))[0:scale], y_pred[0:scale], color='k', label='y_pred')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270088,) (270088,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape, y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Livia\\Desktop\\photometry_liv\\photometry_preprocessing\\sabatini-glm-workflow\\notebooks\\fitGLM_D1.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Livia/Desktop/photometry_liv/photometry_preprocessing/sabatini-glm-workflow/notebooks/fitGLM_D1.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_params\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "# best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create your model dictonary, this should include all the information you wish to save\n",
    "if modeltype == \"fit\":\n",
    "    model_dict = {'model': model,\n",
    "              'y_pred': y_pred,\n",
    "              'score': score,\n",
    "              'beta': beta,\n",
    "              'intercept': intercept,\n",
    "              'sparse_beta': sparse_beta,}\n",
    "if modeltype == 'tuned':\n",
    "    model_dict = {'model': tuned_model,\n",
    "              'y_pred': y_pred,\n",
    "              'score': score,\n",
    "              'beta': beta,\n",
    "              'best_params': best_params,}\n",
    "    \n",
    "\n",
    "#Save your model dictionary\n",
    "model_path = project_path + '/models'\n",
    "model_name = project_name + '_model.pkl'\n",
    "model_full_path = os.path.join(model_path, model_name)\n",
    "import pickle\n",
    "with open(model_full_path, 'wb') as f:\n",
    "    pickle.dump(model_dict, f)\n",
    "        \n",
    "# glm_fit.save_model(model_dict, project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: \\\\research.files.med.harvard.edu\\\\Neurobio\\\\MICROSCOPE\\\\Livia\\\\glm_output\\A2a_sh_noITI_glm/results/model_fit.png\n"
     ]
    }
   ],
   "source": [
    "save_img = os.path.join(project_path)\n",
    "\n",
    "glm_fit.plot_and_save(save_img, config, y_pred, y_test, beta, df_predictors_shift, format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
